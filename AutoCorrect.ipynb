{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file path\n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus in lower case. \n",
    "    \"\"\"\n",
    "    words = [] \n",
    "    with open('shakespeare.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            words_temp = re.split(r'\\W+', line.rstrip().lower())\n",
    "            for word in words_temp:\n",
    "                if (len(word) != 0):\n",
    "                    words.append(word)\n",
    "     \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_l = process_data('shakespeare.txt')\n",
    "vocab = set(word_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word_l):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "       A set of words representing the corpus.\n",
    "    Output:\n",
    "        A dictionary with kay as a word and value as its frequency\n",
    "    \"\"\"\n",
    "    word_count_dict = {}\n",
    "    word_count_dict = Counter(word_l)\n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_dict = Counter(word_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    \"\"\"\n",
    "    probs = {}  \n",
    "    m = len(word_l)\n",
    "    for word, count in word_count_dict.items():\n",
    "        probs[word] = word_count_dict[word]/m\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = get_probs(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A word \n",
    "    Output:\n",
    "        A list of all possible words obtained by deleting 1 character from the input word\n",
    "    \"\"\"\n",
    "    \n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    delete_l = [L + R[1:] for L, R in split_l if len(R) > 0]\n",
    "    \n",
    "    return delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter(word):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A word \n",
    "    Output:\n",
    "        A list of all possible strings with one adjacent charater switched\n",
    "    \"\"\"\n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    switch_l = [L + R[1] + R[0] + R[2:] for L, R in split_l if len(R) > 1]\n",
    "    \n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A word \n",
    "    Output:\n",
    "        A list of all possible strings where we replaced one letter from the original word\n",
    "    \"\"\"\n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
    "    replace_set = set([L + l + R[1:] for L, R in split_l if len(R) > 0 for l in letters])\n",
    "    replace_set.remove(word)\n",
    "    \n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A word \n",
    "    Output:\n",
    "        A set of all possible strings with one new letter inserted at every offset\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "    insert_l = [L + l + R for L, R in split_l if len(R) >= 0 for l in letters]\n",
    "    \n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A word\n",
    "    Output:\n",
    "        A set of words with one possible edit\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    \n",
    "    \n",
    "    inserts = insert_letter(word)\n",
    "    deletes = delete_letter(word)\n",
    "    replaces = replace_letter(word)\n",
    "    options = inserts + deletes + replaces\n",
    "    for w in options:\n",
    "        edit_one_set.add(w)\n",
    "    if allow_switches:\n",
    "        switches = switch_letter(word)\n",
    "        for w in switches:\n",
    "            edit_one_set.add(w)\n",
    "    \n",
    "    return edit_one_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A word\n",
    "    Output:\n",
    "        A set of strings with all possible two edits\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    one_edits = edit_one_letter(word, allow_switches)\n",
    "    for w in one_edits:\n",
    "        if (len(w) > 0):\n",
    "            edits = edit_one_letter(w, allow_switches)\n",
    "            for w_ in edits:\n",
    "                edit_two_set.add(w_)\n",
    "    \n",
    "    \n",
    "    return edit_two_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrections(word, probs, vocab, n=2):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    if word in vocab:\n",
    "        n_best.append(word)\n",
    "        return n_best\n",
    "    one_edits =  edit_one_letter(word)\n",
    "    for w in one_edits:\n",
    "        if w in vocab:\n",
    "            suggestions.append((w, probs[w]))\n",
    "    if (len(suggestions) < n):        \n",
    "        two_edits =  edit_two_letters(word)\n",
    "        for w in two_edits:\n",
    "            if w in vocab:\n",
    "                suggestions.append((w, probs[w]))\n",
    "    n_best = sorted(suggestions, key = lambda x: -x[1])\n",
    "\n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    '''\n",
    "    Input: \n",
    "        source: a string corresponding to the string you are starting with\n",
    "        target: a string corresponding to the string you want to end with\n",
    "        ins_cost: an integer setting the insert cost\n",
    "        del_cost: an integer setting the delete cost\n",
    "        rep_cost: an integer setting the replace cost\n",
    "    Output:\n",
    "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
    "        med: the minimum edit distance (med) required to convert the source string to the target\n",
    "    '''\n",
    "    m = len(source) \n",
    "    n = len(target) \n",
    "    D = np.zeros((m+1, n+1), dtype=int) \n",
    "    \n",
    "    for row in range(1,m+1): # e\n",
    "        D[row,0] = D[row-1,0] + 1\n",
    "        \n",
    "    for col in range(1,n+1): \n",
    "        D[0,col] = D[0, col-1] + 1\n",
    "        \n",
    "    for row in range(1,m+1): \n",
    "        for col in range(1, n+1):\n",
    "            r_cost = rep_cost \n",
    "            if source[row-1] == target[col-1]:\n",
    "                r_cost = 0\n",
    "            D[row,col] = min(D[row-1,col] + del_cost, D[row, col-1] + ins_cost, D[row-1, col-1] + r_cost)\n",
    "    med = D[m,n]\n",
    "    \n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('at', 0.0024433916514343267),\n",
       " ('hath', 0.002144962136755325),\n",
       " ('can', 0.0019211400007460738),\n",
       " ('act', 0.0006528145633603163),\n",
       " ('call', 0.0005409034953556906),\n",
       " ('hate', 0.00046629611668594026),\n",
       " ('eat', 0.00022382213600925132),\n",
       " ('care', 0.00022382213600925132),\n",
       " ('came', 0.0002051702913418137),\n",
       " ('case', 0.0001865184466743761),\n",
       " ('cat', 0.00014921475733950087),\n",
       " ('camp', 0.00014921475733950087),\n",
       " ('late', 0.00014921475733950087),\n",
       " ('cat', 0.00014921475733950087),\n",
       " ('catch', 0.00013056291267206328),\n",
       " ('date', 0.00011191106800462566),\n",
       " ('rate', 9.325922333718805e-05),\n",
       " ('wait', 9.325922333718805e-05),\n",
       " ('cap', 7.460737866975044e-05),\n",
       " ('bath', 7.460737866975044e-05),\n",
       " ('cut', 7.460737866975044e-05),\n",
       " ('gate', 7.460737866975044e-05),\n",
       " ('oath', 7.460737866975044e-05),\n",
       " ('cast', 7.460737866975044e-05),\n",
       " ('acts', 5.595553400231283e-05),\n",
       " ('sat', 5.595553400231283e-05),\n",
       " ('city', 5.595553400231283e-05),\n",
       " ('gait', 3.730368933487522e-05),\n",
       " ('pate', 1.865184466743761e-05),\n",
       " ('bait', 1.865184466743761e-05),\n",
       " ('bate', 1.865184466743761e-05),\n",
       " ('fate', 1.865184466743761e-05),\n",
       " ('cars', 1.865184466743761e-05),\n",
       " ('cam', 1.865184466743761e-05),\n",
       " ('eats', 1.865184466743761e-05),\n",
       " ('carp', 1.865184466743761e-05),\n",
       " ('batt', 1.865184466743761e-05),\n",
       " ('hats', 1.865184466743761e-05)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_corrections(\"cati\", probs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('on', 0.0033200283508038947),\n",
       " ('man', 0.0013242809713880702),\n",
       " ('men', 0.0008766366993695677),\n",
       " ('son', 0.0007274219420300668),\n",
       " ('won', 0.0001678666020069385),\n",
       " ('moan', 9.325922333718805e-05),\n",
       " ('moon', 5.595553400231283e-05),\n",
       " ('morn', 5.595553400231283e-05),\n",
       " ('mov', 3.730368933487522e-05),\n",
       " ('con', 1.865184466743761e-05),\n",
       " ('non', 1.865184466743761e-05),\n",
       " ('mow', 1.865184466743761e-05)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_corrections(\"mon\", probs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('at', 0.0024433916514343267),\n",
       " ('may', 0.002014399224083262),\n",
       " ('man', 0.0013242809713880702),\n",
       " ('eat', 0.00022382213600925132),\n",
       " ('mad', 0.0001678666020069385),\n",
       " ('cat', 0.00014921475733950087),\n",
       " ('met', 9.325922333718805e-05),\n",
       " ('sat', 5.595553400231283e-05),\n",
       " ('mak', 3.730368933487522e-05),\n",
       " ('map', 3.730368933487522e-05),\n",
       " ('mar', 1.865184466743761e-05),\n",
       " ('meat', 1.865184466743761e-05)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_corrections(\"mat\", probs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
